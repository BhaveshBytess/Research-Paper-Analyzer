We propose the Reflective Cognitive Architecture (RCA), a novel framework coordinating multiple LLMs to enhance clinical decision support by balancing accuracy and explainability. RCA employs iterative rule refinement and distribution-aware checks to improve logic and reasoning. Evaluated on one private and two public datasets against 22 baselines, RCA achieves up to 40% relative improvement in accuracy and robustness while generating clear, evidence-based explanations. Key results include RCA + GPT-4.1 scoring 8.03 on the CRT dataset, outperforming traditional MLs and LLM-based methods.